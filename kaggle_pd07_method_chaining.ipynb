{
  "cells": [
    {
      "metadata": {
        "_uuid": "58335a1bb472e68aaddc32827fdb99d9d44e4ab2",
        "_cell_guid": "14c68aad-0435-454b-8bc7-6556f60b034e"
      },
      "cell_type": "markdown",
      "source": "# Method chaining workbook\n\n## Introduction\n\nThis is the workbook component of the \"Method chaining\" section of the tutorial. For the reference component, click [here](https://www.kaggle.com/residentmario/method-chaining-reference).\n\nThis is the last workbook in the tutorial. Congratulations! In this section we will put all of the things that we learned together to do some truly interesting things with some datasets. The exercises in this section are therefore also quite difficult! Try using method chaning syntax while working through the examples that follow, and make studious use of the hints that we provide."
    },
    {
      "metadata": {
        "_uuid": "a4f1f60fb1c5c7d744bc9089fc58b4be8d082947",
        "_cell_guid": "0559dd85-e762-4699-95d6-28840f18e910",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\npd.set_option('max_rows', 5)\nfrom learntools.advanced_pandas.method_chaining import *\n\nchess_games = pd.read_csv(\"../input/chess/games.csv\")",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2477f759f3c11e964f50c583f211f6e324bad518",
        "_cell_guid": "3070c6b9-5ac4-4604-91f7-5fe9128ccfb2"
      },
      "cell_type": "markdown",
      "source": "# Checking Answers\n\n**Check your answers in each exercise using the  `check_qN` function** (replacing `N` with the number of the exercise). For example here's how you would check an incorrect answer to exercise 1:"
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "b8490e33adb514ab0bd4b92911fb4d1c9e018b51",
        "_cell_guid": "47ec828b-f315-4126-a534-5d0b5af6f973",
        "trusted": false
      },
      "cell_type": "code",
      "source": "check_q1(pd.DataFrame())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dd23107bed53e3ab1ece7a091ed29d2dd826c6c5",
        "_cell_guid": "96b7eed1-d290-4da7-aeb0-92e7381e7db1"
      },
      "cell_type": "markdown",
      "source": "If you get stuck, **use the `answer_qN` function to see the code with the correct answer.**\n\nFor the first set of questions, running the `check_qN` on the correct answer returns `True`.\n\nFor the second set of questions, using this function to check a correct answer will present an informative graph."
    },
    {
      "metadata": {
        "_uuid": "76a8860fa325d3324028437fa4b6ec392e7a279e",
        "_cell_guid": "0d4748cd-9a43-4928-9ba3-9c42a4bfbb0d"
      },
      "cell_type": "markdown",
      "source": "## Exercises\n\nView your data by running the cell below"
    },
    {
      "metadata": {
        "_uuid": "34bb03034a84edb302cdb4bdff4854aa25a17dae",
        "_cell_guid": "543c4672-bc57-4fd4-9e70-9ccbf43fd4c0",
        "trusted": true
      },
      "cell_type": "code",
      "source": "chess_games.head()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "         id     ...       opening_ply\n0  TZJHLljE     ...                 5\n1  l1NXvwaE     ...                 4\n2  mIICvQHh     ...                 3\n3  kWKvrqYL     ...                 3\n4  9tXo1AUZ     ...                 5\n\n[5 rows x 16 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rated</th>\n      <th>created_at</th>\n      <th>last_move_at</th>\n      <th>turns</th>\n      <th>victory_status</th>\n      <th>winner</th>\n      <th>increment_code</th>\n      <th>white_id</th>\n      <th>white_rating</th>\n      <th>black_id</th>\n      <th>black_rating</th>\n      <th>moves</th>\n      <th>opening_eco</th>\n      <th>opening_name</th>\n      <th>opening_ply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TZJHLljE</td>\n      <td>False</td>\n      <td>1.504210e+12</td>\n      <td>1.504210e+12</td>\n      <td>13</td>\n      <td>outoftime</td>\n      <td>white</td>\n      <td>15+2</td>\n      <td>bourgris</td>\n      <td>1500</td>\n      <td>a-00</td>\n      <td>1191</td>\n      <td>d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...</td>\n      <td>D10</td>\n      <td>Slav Defense: Exchange Variation</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>l1NXvwaE</td>\n      <td>True</td>\n      <td>1.504130e+12</td>\n      <td>1.504130e+12</td>\n      <td>16</td>\n      <td>resign</td>\n      <td>black</td>\n      <td>5+10</td>\n      <td>a-00</td>\n      <td>1322</td>\n      <td>skinnerua</td>\n      <td>1261</td>\n      <td>d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...</td>\n      <td>B00</td>\n      <td>Nimzowitsch Defense: Kennedy Variation</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mIICvQHh</td>\n      <td>True</td>\n      <td>1.504130e+12</td>\n      <td>1.504130e+12</td>\n      <td>61</td>\n      <td>mate</td>\n      <td>white</td>\n      <td>5+10</td>\n      <td>ischia</td>\n      <td>1496</td>\n      <td>a-00</td>\n      <td>1500</td>\n      <td>e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...</td>\n      <td>C20</td>\n      <td>King's Pawn Game: Leonardis Variation</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>kWKvrqYL</td>\n      <td>True</td>\n      <td>1.504110e+12</td>\n      <td>1.504110e+12</td>\n      <td>61</td>\n      <td>mate</td>\n      <td>white</td>\n      <td>20+0</td>\n      <td>daniamurashov</td>\n      <td>1439</td>\n      <td>adivanov2009</td>\n      <td>1454</td>\n      <td>d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...</td>\n      <td>D02</td>\n      <td>Queen's Pawn Game: Zukertort Variation</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9tXo1AUZ</td>\n      <td>True</td>\n      <td>1.504030e+12</td>\n      <td>1.504030e+12</td>\n      <td>95</td>\n      <td>mate</td>\n      <td>white</td>\n      <td>30+3</td>\n      <td>nik221107</td>\n      <td>1523</td>\n      <td>adivanov2009</td>\n      <td>1469</td>\n      <td>e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...</td>\n      <td>C41</td>\n      <td>Philidor Defense</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "9404e800ee7ca838451d8f420fa23f828fbc06f1",
        "_cell_guid": "be821524-d37d-4128-9d72-105ad898cb48"
      },
      "cell_type": "markdown",
      "source": "**Exercise 1**: It's well-known that in the game of chess, white has a slight first-mover advantage against black. Can you measure this effect in this dataset? Use the `winner` column to create a `pandas` `Series` showing how often white wins, how often black wins, and how often the result is a tie, as a ratio of total games played. In other words, a `Series` that looks something like this:\n\n    white    0.48\n    black    0.44\n    draw     0.08\n    Name: winner, dtype: float64\n    \nHint: use `len` to get the length of the initial `DataFrame`, e.g. the count of all games played."
    },
    {
      "metadata": {
        "_uuid": "e06e76a60dea3fb40799c213167f2dbfde052cc9",
        "_cell_guid": "9a89d5ac-5294-4714-a02f-71aa02cb3b95",
        "trusted": true
      },
      "cell_type": "code",
      "source": "chess_games.winner.value_counts() / len(chess_games)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "white    0.498604\nblack    0.454033\ndraw     0.047363\nName: winner, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "0afa1a01f6339744f117e40bc564bb8199117fba",
        "_cell_guid": "9e7cc907-78c8-4771-8767-433b26a501fe"
      },
      "cell_type": "markdown",
      "source": "**Exercise 2**: The `opening_name` field of the `chess_games` dataset provides interesting data on what the most commonly used chess openings are.  However, it gives a bit _too_ much detail, including information on the variation used for the most common opening types. For example, rather than giving `Queen's Pawn Game`, the dataset often includes `Queen's Pawn Game: Zukertort Variation`.\n\nThis makes it a bit difficult to use for categorical purposes. Here's a function that can be used to separate out the \"opening archetype\":\n\n ```python\n lambda n: n.split(\":\")[0].split(\"|\")[0].split(\"#\")[0].strip()\n ```\n\nUse this function to parse the `opening_name` field and generate a `pandas` `Series` counting how many times each of the \"opening archetypes\" gets used. Hint: use a map."
    },
    {
      "metadata": {
        "_uuid": "0a87e4d43aacdbc602c45edebd2cbc17828a8215",
        "_cell_guid": "bec47114-46d5-4224-8fe8-a892672e087a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "chess_games.opening_name.map(lambda n: n.split(\":\")[0].split(\"|\")[0].split(\"#\")[0].strip()).value_counts()",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "Sicilian Defense    2632\nFrench Defense      1412\n                    ... \nDoery Defense          1\nValencia Opening       1\nName: opening_name, Length: 143, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "4c00c11c77310fbbb1d80c7ab0b9c2cec6a85d8c",
        "_cell_guid": "77d52589-e77b-4f2a-8368-b648542d7cfd"
      },
      "cell_type": "markdown",
      "source": "**Exercise 3**: In this dataset various players play variably number of games. Group the games by `{white_id, victory_status}` and count how many times each white player ended the game in `mate` , `draw`, `resign`, etcetera. The name of the column counting how many times each outcome occurred should be `n` (hint: `rename` or `assign` may help)."
    },
    {
      "metadata": {
        "_uuid": "4c1d624a0e13e0084618a0b07eee93a63e547c51",
        "_cell_guid": "5bf66581-b084-4759-95a0-5bcb3eb7add3",
        "trusted": true
      },
      "cell_type": "code",
      "source": "chess_games['n'] = 0\nchess_games.groupby(['white_id', 'victory_status']).n.count()",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "white_id             victory_status\n--jim--              mate              1\n-l-_jedi_knight_-l-  mate              1\n                                      ..\nzzzbbb               resign            1\nzzzimon              resign            1\nName: n, Length: 11489, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "d8270a4063738d6a9cfc1f475e0b5b94e36689a2",
        "_cell_guid": "fbb9dbed-4013-43d2-aa6a-23b4b3553e41"
      },
      "cell_type": "markdown",
      "source": "**Exercise 4**: There are a lot of players in the dataset who have only played one or a small handful of games. Create a `DataFrame` like the one in the previous exercise, but only include users who are in the top 20 users by number of games played. See if you can do this using method chaining alone! Hint: reuse the code from the previous example. Then, use `pipe`."
    },
    {
      "metadata": {
        "_uuid": "94205b5e1b027801f096d329be50202c6c25e48c",
        "_cell_guid": "a1174d88-e96a-4045-880d-9b7cf23a2ebf",
        "trusted": true
      },
      "cell_type": "code",
      "source": "chess_games.assign(n=0).groupby(['white_id', 'victory_status']).n.count().reset_index().pipe(lambda df: df.loc[df.white_id.isin(chess_games.white_id.value_counts().head(20).index)])",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "         white_id victory_status   n\n9      1240100948           draw   3\n10     1240100948           mate   7\n...           ...            ...  ..\n10907    vovkakuz      outoftime   4\n10908    vovkakuz         resign  23\n\n[72 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>white_id</th>\n      <th>victory_status</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>1240100948</td>\n      <td>draw</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1240100948</td>\n      <td>mate</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10907</th>\n      <td>vovkakuz</td>\n      <td>outoftime</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10908</th>\n      <td>vovkakuz</td>\n      <td>resign</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c28a91527be0920116c8bf017a766fd28bf3343c",
        "_cell_guid": "bd59912b-744e-4d7b-8f86-e787d7121d46"
      },
      "cell_type": "markdown",
      "source": "Next, let's do some visual exercises.\n\nThe next exercise uses the following dataset:"
    },
    {
      "metadata": {
        "_uuid": "96a82b2ab00aeeb1c69806201713de3ab31c64e2",
        "_cell_guid": "f5ac1f2a-4bc5-4c6a-9e77-9f1836aa9f27",
        "trusted": true
      },
      "cell_type": "code",
      "source": "kepler = pd.read_csv(\"../input/kepler-exoplanet-search-results/cumulative.csv\")\nkepler",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "      rowid     kepid kepoi_name    ...             ra        dec koi_kepmag\n0         1  10797460  K00752.01    ...      291.93423  48.141651     15.347\n1         2  10797460  K00752.02    ...      291.93423  48.141651     15.347\n...     ...       ...        ...    ...            ...        ...        ...\n9562   9563  10147276  K07987.01    ...      294.16489  47.176281     15.385\n9563   9564  10156110  K07989.01    ...      297.00977  47.121021     14.826\n\n[9564 rows x 50 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rowid</th>\n      <th>kepid</th>\n      <th>kepoi_name</th>\n      <th>kepler_name</th>\n      <th>koi_disposition</th>\n      <th>koi_pdisposition</th>\n      <th>koi_score</th>\n      <th>koi_fpflag_nt</th>\n      <th>koi_fpflag_ss</th>\n      <th>koi_fpflag_co</th>\n      <th>koi_fpflag_ec</th>\n      <th>koi_period</th>\n      <th>koi_period_err1</th>\n      <th>koi_period_err2</th>\n      <th>koi_time0bk</th>\n      <th>koi_time0bk_err1</th>\n      <th>koi_time0bk_err2</th>\n      <th>koi_impact</th>\n      <th>koi_impact_err1</th>\n      <th>koi_impact_err2</th>\n      <th>koi_duration</th>\n      <th>koi_duration_err1</th>\n      <th>koi_duration_err2</th>\n      <th>koi_depth</th>\n      <th>koi_depth_err1</th>\n      <th>koi_depth_err2</th>\n      <th>koi_prad</th>\n      <th>koi_prad_err1</th>\n      <th>koi_prad_err2</th>\n      <th>koi_teq</th>\n      <th>koi_teq_err1</th>\n      <th>koi_teq_err2</th>\n      <th>koi_insol</th>\n      <th>koi_insol_err1</th>\n      <th>koi_insol_err2</th>\n      <th>koi_model_snr</th>\n      <th>koi_tce_plnt_num</th>\n      <th>koi_tce_delivname</th>\n      <th>koi_steff</th>\n      <th>koi_steff_err1</th>\n      <th>koi_steff_err2</th>\n      <th>koi_slogg</th>\n      <th>koi_slogg_err1</th>\n      <th>koi_slogg_err2</th>\n      <th>koi_srad</th>\n      <th>koi_srad_err1</th>\n      <th>koi_srad_err2</th>\n      <th>ra</th>\n      <th>dec</th>\n      <th>koi_kepmag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>10797460</td>\n      <td>K00752.01</td>\n      <td>Kepler-227 b</td>\n      <td>CONFIRMED</td>\n      <td>CANDIDATE</td>\n      <td>1.000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9.488036</td>\n      <td>0.000028</td>\n      <td>-0.000028</td>\n      <td>170.53875</td>\n      <td>0.00216</td>\n      <td>-0.00216</td>\n      <td>0.146</td>\n      <td>0.318</td>\n      <td>-0.146</td>\n      <td>2.9575</td>\n      <td>0.0819</td>\n      <td>-0.0819</td>\n      <td>615.8</td>\n      <td>19.5</td>\n      <td>-19.5</td>\n      <td>2.26</td>\n      <td>0.26</td>\n      <td>-0.15</td>\n      <td>793.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>93.59</td>\n      <td>29.45</td>\n      <td>-16.65</td>\n      <td>35.8</td>\n      <td>1.0</td>\n      <td>q1_q17_dr25_tce</td>\n      <td>5455.0</td>\n      <td>81.0</td>\n      <td>-81.0</td>\n      <td>4.467</td>\n      <td>0.064</td>\n      <td>-0.096</td>\n      <td>0.927</td>\n      <td>0.105</td>\n      <td>-0.061</td>\n      <td>291.93423</td>\n      <td>48.141651</td>\n      <td>15.347</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>10797460</td>\n      <td>K00752.02</td>\n      <td>Kepler-227 c</td>\n      <td>CONFIRMED</td>\n      <td>CANDIDATE</td>\n      <td>0.969</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>54.418383</td>\n      <td>0.000248</td>\n      <td>-0.000248</td>\n      <td>162.51384</td>\n      <td>0.00352</td>\n      <td>-0.00352</td>\n      <td>0.586</td>\n      <td>0.059</td>\n      <td>-0.443</td>\n      <td>4.5070</td>\n      <td>0.1160</td>\n      <td>-0.1160</td>\n      <td>874.8</td>\n      <td>35.5</td>\n      <td>-35.5</td>\n      <td>2.83</td>\n      <td>0.32</td>\n      <td>-0.19</td>\n      <td>443.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.11</td>\n      <td>2.87</td>\n      <td>-1.62</td>\n      <td>25.8</td>\n      <td>2.0</td>\n      <td>q1_q17_dr25_tce</td>\n      <td>5455.0</td>\n      <td>81.0</td>\n      <td>-81.0</td>\n      <td>4.467</td>\n      <td>0.064</td>\n      <td>-0.096</td>\n      <td>0.927</td>\n      <td>0.105</td>\n      <td>-0.061</td>\n      <td>291.93423</td>\n      <td>48.141651</td>\n      <td>15.347</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9562</th>\n      <td>9563</td>\n      <td>10147276</td>\n      <td>K07987.01</td>\n      <td>NaN</td>\n      <td>FALSE POSITIVE</td>\n      <td>FALSE POSITIVE</td>\n      <td>0.021</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.681402</td>\n      <td>0.000002</td>\n      <td>-0.000002</td>\n      <td>132.18175</td>\n      <td>0.00285</td>\n      <td>-0.00285</td>\n      <td>0.147</td>\n      <td>0.309</td>\n      <td>-0.147</td>\n      <td>0.8650</td>\n      <td>0.1620</td>\n      <td>-0.1620</td>\n      <td>103.6</td>\n      <td>14.7</td>\n      <td>-14.7</td>\n      <td>1.07</td>\n      <td>0.36</td>\n      <td>-0.11</td>\n      <td>2218.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5713.41</td>\n      <td>5675.74</td>\n      <td>-1836.94</td>\n      <td>12.3</td>\n      <td>1.0</td>\n      <td>q1_q17_dr25_tce</td>\n      <td>6173.0</td>\n      <td>193.0</td>\n      <td>-236.0</td>\n      <td>4.447</td>\n      <td>0.056</td>\n      <td>-0.224</td>\n      <td>1.041</td>\n      <td>0.341</td>\n      <td>-0.114</td>\n      <td>294.16489</td>\n      <td>47.176281</td>\n      <td>15.385</td>\n    </tr>\n    <tr>\n      <th>9563</th>\n      <td>9564</td>\n      <td>10156110</td>\n      <td>K07989.01</td>\n      <td>NaN</td>\n      <td>FALSE POSITIVE</td>\n      <td>FALSE POSITIVE</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.856035</td>\n      <td>0.000064</td>\n      <td>-0.000064</td>\n      <td>135.99330</td>\n      <td>0.01080</td>\n      <td>-0.01080</td>\n      <td>0.134</td>\n      <td>0.323</td>\n      <td>-0.134</td>\n      <td>3.0780</td>\n      <td>0.2830</td>\n      <td>-0.2830</td>\n      <td>76.7</td>\n      <td>10.8</td>\n      <td>-10.8</td>\n      <td>1.05</td>\n      <td>0.36</td>\n      <td>-0.12</td>\n      <td>1266.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>607.42</td>\n      <td>600.39</td>\n      <td>-194.33</td>\n      <td>8.2</td>\n      <td>1.0</td>\n      <td>q1_q17_dr25_tce</td>\n      <td>6469.0</td>\n      <td>158.0</td>\n      <td>-225.0</td>\n      <td>4.385</td>\n      <td>0.054</td>\n      <td>-0.216</td>\n      <td>1.193</td>\n      <td>0.410</td>\n      <td>-0.137</td>\n      <td>297.00977</td>\n      <td>47.121021</td>\n      <td>14.826</td>\n    </tr>\n  </tbody>\n</table>\n<p>9564 rows × 50 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "4e97a338fe718b61703699a4f6b8e81c238f63b6",
        "_cell_guid": "ed30c948-bf7d-4014-b46e-e6764b32887c"
      },
      "cell_type": "markdown",
      "source": "**Exercise 5**: The Kepler space observatory is in the business of finding potential exoplanets (planets orbiting stars other suns) and, after collecting the evidence, generating whether or not to confirm, decline to confirm, or deny that a given space body is, in fact, an exoplanet. In the dataset above, the \"before\" status of the body is `koi_pdisposition`, and the \"after\" status is `koi_disposition`. \n\nUsing the dataset above, generate a `Series` counting all of the possible transitions between pre-disposition and post-disposition. In other words, generate a `Series` whose index is a `MultiIndex` based on the `{koi_pdisposition, koi_disposition}` fields, and whose values is a count of how many times each possible combination occurred."
    },
    {
      "metadata": {
        "_uuid": "04f4696abbce980b6c265715ce6af24c055f837a",
        "_cell_guid": "c7f220fc-638f-49e8-bd4d-52e14e451ce7",
        "trusted": true
      },
      "cell_type": "code",
      "source": "kepler.assign(n=0).groupby(['koi_pdisposition', 'koi_disposition']).n.count()",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "koi_pdisposition  koi_disposition\nCANDIDATE         CANDIDATE          2248\n                  CONFIRMED          2248\nFALSE POSITIVE    CONFIRMED            45\n                  FALSE POSITIVE     5023\nName: n, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "ceececcbd0f41b807d173ced0672320933cfa99c",
        "_cell_guid": "7225ca0a-2fa8-4bd2-b286-2731bdac0982"
      },
      "cell_type": "markdown",
      "source": "The next few exercises use the following datasets:"
    },
    {
      "metadata": {
        "_uuid": "c776c108c02cce4fd1152b6330ccdac899ce8b55",
        "_cell_guid": "fda2b4e8-08e2-44b0-abc9-2160e63e64bc",
        "trusted": true
      },
      "cell_type": "code",
      "source": "wine_reviews = pd.read_csv(\"../input/wine-reviews/winemag-data-130k-v2.csv\", index_col=0)\nramen_reviews = pd.read_csv(\"../input/ramen-ratings/ramen-ratings.csv\", index_col=0)\nprint(wine_reviews.head())\nprint(ramen_reviews.head())",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "    country         ...                        winery\n0     Italy         ...                       Nicosia\n1  Portugal         ...           Quinta dos Avidagos\n2        US         ...                     Rainstorm\n3        US         ...                    St. Julian\n4        US         ...                  Sweet Cheeks\n\n[5 rows x 13 columns]\n                   Brand   ...   Top Ten\nReview #                   ...          \n2580           New Touch   ...       NaN\n2579            Just Way   ...       NaN\n2578              Nissin   ...       NaN\n2577             Wei Lih   ...       NaN\n2576      Ching's Secret   ...       NaN\n\n[5 rows x 6 columns]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "a26f10615034d4bd565f56764bf7a62b4ff0544e",
        "_cell_guid": "c8eae2c9-5dad-4969-8250-8738f763a909"
      },
      "cell_type": "markdown",
      "source": "**Exercise 6**: As we demonstrated in previous workbooks, the `points` column in the `wine_reviews` dataset is measured on a 20-point scale between 80 and 100. Create a `Series` which normalizes the ratings so that they fit on a 1-to-5 scale instead (e.g. a score of 80 translates to 1 star, while a score of 100 is five stars). Set the `Series` name to \"Wine Ratings\", and sort by index value (ascending)."
    },
    {
      "metadata": {
        "_uuid": "b694074c3711bf9be8eafa45a0d48b3478afe257",
        "_cell_guid": "54717874-8186-4b2b-bd5e-2f2883d1ab8e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "wine_reviews.points.map(lambda p: (p - 80) // 4).value_counts().sort_index().rename_axis('Wine Ratings')",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "Wine Ratings\n0     5950\n1    45543\n     ...  \n4      862\n5       19\nName: points, Length: 6, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "b1d5ffc806de05d79260977923dba80468db7c79",
        "_cell_guid": "0e73353b-5091-43c3-83db-50e8b9e42759"
      },
      "cell_type": "markdown",
      "source": "**Exercise 7**: The `Stars` column in the `ramen_reviews` dataset is the ramen equivalent to the similar data points in `wine_reviews`. Luckily it is already on a 0-to-5 scale, but it has some different problems...create a `Series` counting how many ramens earned each of the possible scores in the dataset. Convert the `Series` to the `float64` dtype and drop rames whose rating is `\"Unrated\"`. Set the name of the `Series` to \"Ramen Ratings\". Sort by index value (ascending)."
    },
    {
      "metadata": {
        "_uuid": "85c2e6a18fcaabadaaa89ee3cb634db5e5e1a2e3",
        "_cell_guid": "1c591a14-c68c-42de-bcd8-04c2317571b2",
        "trusted": true
      },
      "cell_type": "code",
      "source": "ramen_reviews.Stars.replace('Unrated', None).dropna().value_counts().astype(float).sort_index().rename_axis('Ramen Ratings')",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "Ramen Ratings\n0       26.0\n0.1      1.0\n        ... \n5.0     10.0\n5.00     7.0\nName: Stars, Length: 50, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "a80054f5a7bfa75c7bfbeacc65a480837291ab1d",
        "_cell_guid": "0cba2cab-5315-4a3c-b1f4-8f07da6901a4"
      },
      "cell_type": "markdown",
      "source": "**Exercise 8:**: We can see from the result of the previous exercise that whilst the wine reviewers stick to a strict 20-point scale, ramen reviews occassionally deviate into fractional numbers. Modify your answer to the previous exercise by rounding review scores to the nearest half-point (so 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, or 5)."
    },
    {
      "metadata": {
        "_uuid": "b27106dfbd02957b9257e4d11066e8ac16701c87",
        "_cell_guid": "f9e20b2c-4e22-44bf-9693-5ad7de555b9f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "ramen_reviews.Stars.replace('Unrated', None).dropna().astype(float).map(lambda s: round(s * 2) / 2).value_counts().sort_index().rename_axis('Ramen Ratings')",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "Ramen Ratings\n0.0     38\n0.5     14\n      ... \n4.5    140\n5.0    450\nName: Stars, Length: 11, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "b625a31d8580c32b17db77ef838c6dbe9de5eb23",
        "_cell_guid": "a82d9542-13c4-42b7-a71d-d02682947216"
      },
      "cell_type": "markdown",
      "source": "# Congratulations\n\nYou've finished the Pandas track.  Many data scientist feel efficiency with Pandas is the most useful and practical skill they have, because it allows you to progress quickly in any project you have.\n\nYou can take advantage of your Pandas skills by entering a [Kaggle Competition](https://www.kaggle.com/competitions) or answering a question you find interesting using [Kaggle Datasets](https://www.kaggle.com/datasets)."
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}